# MA C.'s Daily Paper Of Interest - December, 2023

# Index

- [2023-12-22](#2023-12-22)
  - [1. Speech Translation with Large Language Models: An Industrial Practice](#2023-12-22-1)
  
- [2023-12-21](#2023-12-21)
  - [1. LlaMaVAE: Guiding Large Language Model Generation via Continuous Latent Sentence Spaces](#2023-12-21-1)

  - [2. Contextual Code Switching for Machine Translation using Language Models](#2023-12-21-2)

  - [3. In Generative AI we Trust: Can Chatbots Effectively Verify Political Information?](#2023-12-21-3)

  - [4. Retrieval-augmented Multilingual Knowledge Editing](#2023-12-21-4)

  - [5. Machine Mindset: An MBTI Exploration of Large Language Models](#2023-12-21-5)

  - [6. Enhancing Consistency in Multimodal Dialogue System Using LLM with Dialogue Scenario](#2023-12-21-6)

  - [7. Fine-tuning Large Language Models for Adaptive Machine Translation](#2023-12-21-7)

  - [8. Learning and Forgetting Unsafe Examples in Large Language Models](#2023-12-21-8)

  - [9. Turning English-centric LLMs Into Polyglots: How Much Multilinguality Is Needed?](#2023-12-21-9)

  - [10. Is post-editing really faster than human translation?](#2023-12-21-10)

  - [11. An Empirical study of Unsupervised Neural Machine Translation: analyzing NMT output, model's behavior and sentences' contribution](#2023-12-21-11)

  - [12. When Parameter-efficient Tuning Meets General-purpose Vision-language Models](#2023-12-21-12)

  - [13. Stable Distillation: Regularizing Continued Pre-training for Low-Resource Automatic Speech Recognition](#2023-12-21-13)

  - [14. Towards Better Serialization of Tabular Data for Few-shot Classification](#2023-12-21-14)

- [2023-11-30](#2023-11-30)
  - [1. SenTest: Evaluating Robustness of Sentence Encoders](#2023-11-30-1)

- [Other Columns](https://github.com/EriCongMa/AI_Collections/blob/main/Daily_arXiv/AIKT-MAC-Daily-POI-index.md)



# 2023-12-22

[Return to Index](#Index)



<h2 id="2023-12-22-1">1. Speech Translation with Large Language Models: An Industrial Practice
</h2>

Title: [Speech Translation with Large Language Models: An Industrial Practice](https://arxiv.org/abs/2312.13585)

Authors: [Zhichao Huang](https://arxiv.org/search/cs?searchtype=author&query=Huang,+Z), [Rong Ye](https://arxiv.org/search/cs?searchtype=author&query=Ye,+R), [Tom Ko](https://arxiv.org/search/cs?searchtype=author&query=Ko,+T), [Qianqian Dong](https://arxiv.org/search/cs?searchtype=author&query=Dong,+Q), [Shanbo Cheng](https://arxiv.org/search/cs?searchtype=author&query=Cheng,+S), [Mingxuan Wang](https://arxiv.org/search/cs?searchtype=author&query=Wang,+M), [Hang Li](https://arxiv.org/search/cs?searchtype=author&query=Li,+H)

> Given the great success of large language models (LLMs) across various tasks, in this paper, we introduce LLM-ST, a novel and effective speech translation model constructed upon a pre-trained LLM. By integrating the large language model (LLM) with a speech encoder and employing multi-task instruction tuning, LLM-ST can produce accurate timestamped transcriptions and translations, even from long audio inputs. Furthermore, our findings indicate that the implementation of Chain-of-Thought (CoT) prompting can yield advantages in the context of LLM-ST. Through rigorous experimentation on English and Chinese datasets, we showcase the exceptional performance of LLM-ST, establishing a new benchmark in the field of speech translation. Demo: [this https URL](https://speechtranslation.github.io/llm-st/).

| Comments: | Technical report. 13 pages. Demo: [this https URL](https://speechtranslation.github.io/llm-st/) |
| --------- | ------------------------------------------------------------ |
| Subjects: | **Computation and Language (cs.CL)**; Sound (cs.SD); Audio and Speech Processing (eess.AS) |
| Cite as:  | **[arXiv:2312.13585](https://arxiv.org/abs/2312.13585) [cs.CL]** |
|           | (or **[arXiv:2312.13585v1](https://arxiv.org/abs/2312.13585v1) [cs.CL]** for this version) |
|           | https://doi.org/10.48550/arXiv.2312.13585Focus to learn more |



# 2023-12-21

[Return to Index](#Index)



<h2 id="2023-12-21-1">1. LlaMaVAE: Guiding Large Language Model Generation via Continuous Latent Sentence Spaces
</h2>

Title: [LlaMaVAE: Guiding Large Language Model Generation via Continuous Latent Sentence Spaces](https://arxiv.org/abs/2312.13208)

Authors: [Yingji Zhang](https://arxiv.org/search/cs?searchtype=author&query=Zhang,+Y), [Danilo S. Carvalho](https://arxiv.org/search/cs?searchtype=author&query=Carvalho,+D+S), [Ian Pratt-Hartmann](https://arxiv.org/search/cs?searchtype=author&query=Pratt-Hartmann,+I), [AndrÃ© Freitas](https://arxiv.org/search/cs?searchtype=author&query=Freitas,+A)

> Deep generative neural networks, such as Variational AutoEncoders (VAEs), offer an opportunity to better understand and control language models from the perspective of sentence-level latent spaces. To combine the controllability of VAE latent spaces with the state-of-the-art performance of recent large language models (LLMs), we present in this work LlaMaVAE, which combines expressive encoder and decoder models (sentenceT5 and LlaMA) with a VAE architecture, aiming to provide better text generation control to LLMs. In addition, to conditionally guide the VAE generation, we investigate a new approach based on flow-based invertible neural networks (INNs) named Invertible CVAE. Experimental results reveal that LlaMaVAE can outperform the previous state-of-the-art VAE language model, Optimus, across various tasks, including language modelling, semantic textual similarity and definition modelling. Qualitative analysis on interpolation and traversal experiments also indicates an increased degree of semantic clustering and geometric consistency, which enables better generation control.

| Subjects: | **Computation and Language (cs.CL)**                         |
| --------- | ------------------------------------------------------------ |
| Cite as:  | **[arXiv:2312.13208](https://arxiv.org/abs/2312.13208) [cs.CL]** |
|           | (or **[arXiv:2312.13208v1](https://arxiv.org/abs/2312.13208v1) [cs.CL]** for this version) |





<h2 id="2023-12-21-2">2. Contextual Code Switching for Machine Translation using Language Models
</h2>

Title: [Contextual Code Switching for Machine Translation using Language Models](https://arxiv.org/abs/2312.13179)

Authors: [Arshad Kaji](https://arxiv.org/search/cs?searchtype=author&query=Kaji,+A), [Manan Shah](https://arxiv.org/search/cs?searchtype=author&query=Shah,+M)

> Large language models (LLMs) have exerted a considerable impact on diverse language-related tasks in recent years. Their demonstrated state-of-the-art performance is achieved through methodologies such as zero-shot or few-shot prompting. These models undergo training on extensive datasets that encompass segments of the Internet and subsequently undergo fine-tuning tailored to specific tasks. Notably, they exhibit proficiency in tasks such as translation, summarization, question answering, and creative writing, even in the absence of explicit training for those particular tasks. While they have shown substantial improvement in the multilingual tasks their performance in the code switching, especially for machine translation remains relatively uncharted. In this paper, we present an extensive study on the code switching task specifically for the machine translation task comparing multiple LLMs. Our results indicate that despite the LLMs having promising results in the certain tasks, the models with relatively lesser complexity outperform the multilingual large language models in the machine translation task. We posit that the efficacy of multilingual large language models in contextual code switching is constrained by their training methodologies. In contrast, relatively smaller models, when trained and fine-tuned on bespoke datasets, may yield superior results in comparison to the majority of multilingual models.

| Comments: | 4 pages, 1 figure, 2 tables                                  |
| --------- | ------------------------------------------------------------ |
| Subjects: | **Computation and Language (cs.CL)**                         |
| Cite as:  | **[arXiv:2312.13179](https://arxiv.org/abs/2312.13179) [cs.CL]** |
|           | (or **[arXiv:2312.13179v1](https://arxiv.org/abs/2312.13179v1) [cs.CL]** for this version) |





<h2 id="2023-12-21-3">3. In Generative AI we Trust: Can Chatbots Effectively Verify Political Information?
</h2>

Title: [In Generative AI we Trust: Can Chatbots Effectively Verify Political Information?](https://arxiv.org/abs/2312.13096)

Authors: [Elizaveta Kuznetsova](https://arxiv.org/search/cs?searchtype=author&query=Kuznetsova,+E), [Mykola Makhortykh](https://arxiv.org/search/cs?searchtype=author&query=Makhortykh,+M), [Victoria Vziatysheva](https://arxiv.org/search/cs?searchtype=author&query=Vziatysheva,+V), [Martha Stolze](https://arxiv.org/search/cs?searchtype=author&query=Stolze,+M), [Ani Baghumyan](https://arxiv.org/search/cs?searchtype=author&query=Baghumyan,+A), [Aleksandra Urman](https://arxiv.org/search/cs?searchtype=author&query=Urman,+A)

> This article presents a comparative analysis of the ability of two large language model (LLM)-based chatbots, ChatGPT and Bing Chat, recently rebranded to Microsoft Copilot, to detect veracity of political information. We use AI auditing methodology to investigate how chatbots evaluate true, false, and borderline statements on five topics: COVID-19, Russian aggression against Ukraine, the Holocaust, climate change, and LGBTQ+ related debates. We compare how the chatbots perform in high- and low-resource languages by using prompts in English, Russian, and Ukrainian. Furthermore, we explore the ability of chatbots to evaluate statements according to political communication concepts of disinformation, misinformation, and conspiracy theory, using definition-oriented prompts. We also systematically test how such evaluations are influenced by source bias which we model by attributing specific claims to various political and social actors. The results show high performance of ChatGPT for the baseline veracity evaluation task, with 72 percent of the cases evaluated correctly on average across languages without pre-training. Bing Chat performed worse with a 67 percent accuracy. We observe significant disparities in how chatbots evaluate prompts in high- and low-resource languages and how they adapt their evaluations to political communication concepts with ChatGPT providing more nuanced outputs than Bing Chat. Finally, we find that for some veracity detection-related tasks, the performance of chatbots varied depending on the topic of the statement or the source to which it is attributed. These findings highlight the potential of LLM-based chatbots in tackling different forms of false information in online environments, but also points to the substantial variation in terms of how such potential is realized due to specific factors, such as language of the prompt or the topic.

| Comments: | 22 pages, 8 figures                                          |
| --------- | ------------------------------------------------------------ |
| Subjects: | **Computation and Language (cs.CL)**; Computers and Society (cs.CY) |
| Cite as:  | **[arXiv:2312.13096](https://arxiv.org/abs/2312.13096) [cs.CL]** |
|           | (or **[arXiv:2312.13096v1](https://arxiv.org/abs/2312.13096v1) [cs.CL]** for this version) |





<h2 id="2023-12-21-4">4. Retrieval-augmented Multilingual Knowledge Editing
</h2>

Title: [Retrieval-augmented Multilingual Knowledge Editing](https://arxiv.org/abs/2312.13040)

Authors: [Weixuan Wang](https://arxiv.org/search/cs?searchtype=author&query=Wang,+W), [Barry Haddow](https://arxiv.org/search/cs?searchtype=author&query=Haddow,+B), [Alexandra Birch](https://arxiv.org/search/cs?searchtype=author&query=Birch,+A)

> Knowledge represented in Large Language Models (LLMs) is quite often incorrect and can also become obsolete over time. Updating knowledge via fine-tuning is computationally resource-hungry and not reliable, and so knowledge editing (KE) has developed as an effective and economical alternative to inject new knowledge or to fix factual errors in LLMs. Although there has been considerable interest in this area, current KE research exclusively focuses on the monolingual setting, typically in English. However, what happens if the new knowledge is supplied in one language, but we would like to query the LLM in a different language? To address the problem of multilingual knowledge editing, we propose Retrieval-augmented Multilingual Knowledge Editor (ReMaKE) to update new knowledge in LLMs. ReMaKE can perform model-agnostic knowledge editing in multilingual settings. ReMaKE concatenates the new knowledge retrieved from a multilingual knowledge base with prompts. Our experimental results show that ReMaKE outperforms baseline knowledge editing methods by a significant margin and is the first KE method to work in a multilingual setting. We provide our multilingual knowledge editing dataset (MzsRE) in 12 languages, which along with code, and additional project information is available at [this https URL](https://github.com/Vicky-Wil/ReMaKE).

| Subjects: | **Computation and Language (cs.CL)**                         |
| --------- | ------------------------------------------------------------ |
| Cite as:  | **[arXiv:2312.13040](https://arxiv.org/abs/2312.13040) [cs.CL]** |
|           | (or **[arXiv:2312.13040v1](https://arxiv.org/abs/2312.13040v1) [cs.CL]** for this version) |





<h2 id="2023-12-21-5">5. Machine Mindset: An MBTI Exploration of Large Language Models
</h2>

Title: [Machine Mindset: An MBTI Exploration of Large Language Models](https://arxiv.org/abs/2312.12999)

Authors: [Jiaxi Cui](https://arxiv.org/search/cs?searchtype=author&query=Cui,+J), [Liuzhenghao Lv](https://arxiv.org/search/cs?searchtype=author&query=Lv,+L), [Jing Wen](https://arxiv.org/search/cs?searchtype=author&query=Wen,+J), [Jing Tang](https://arxiv.org/search/cs?searchtype=author&query=Tang,+J), [YongHong Tian](https://arxiv.org/search/cs?searchtype=author&query=Tian,+Y), [Li Yuan](https://arxiv.org/search/cs?searchtype=author&query=Yuan,+L)

> We present a novel approach for integrating Myers-Briggs Type Indicator (MBTI) personality traits into large language models (LLMs), addressing the challenges of personality consistency in personalized AI. Our method, "Machine Mindset," involves a two-phase fine-tuning and Direct Preference Optimization (DPO) to embed MBTI traits into LLMs. This approach ensures that models internalize these traits, offering a stable and consistent personality profile. We demonstrate the effectiveness of our models across various domains, showing alignment between model performance and their respective MBTI traits. The paper highlights significant contributions in the development of personality datasets and a new training methodology for personality integration in LLMs, enhancing the potential for personalized AI applications. We also open-sourced our model and part of the data at \url{[this https URL](https://github.com/PKU-YuanGroup/Machine-Mindset)}.

| Subjects: | **Computation and Language (cs.CL)**                         |
| --------- | ------------------------------------------------------------ |
| Cite as:  | **[arXiv:2312.12999](https://arxiv.org/abs/2312.12999) [cs.CL]** |
|           | (or **[arXiv:2312.12999v1](https://arxiv.org/abs/2312.12999v1) [cs.CL]** for this version) |





<h2 id="2023-12-21-6">6. Enhancing Consistency in Multimodal Dialogue System Using LLM with Dialogue Scenario
</h2>

Title: [Enhancing Consistency in Multimodal Dialogue System Using LLM with Dialogue Scenario](https://arxiv.org/abs/2312.12808)

Authors: [Hiroki Onozeki](https://arxiv.org/search/cs?searchtype=author&query=Onozeki,+H), [Zhiyang Qi](https://arxiv.org/search/cs?searchtype=author&query=Qi,+Z), [Kazuma Akiyama](https://arxiv.org/search/cs?searchtype=author&query=Akiyama,+K), [Ryutaro Asahara](https://arxiv.org/search/cs?searchtype=author&query=Asahara,+R), [Takumasa Kaneko](https://arxiv.org/search/cs?searchtype=author&query=Kaneko,+T), [Michimasa Inaba](https://arxiv.org/search/cs?searchtype=author&query=Inaba,+M)

> This paper describes our dialogue system submitted to Dialogue Robot Competition 2023. The system's task is to help a user at a travel agency decide on a plan for visiting two sightseeing spots in Kyoto City that satisfy the user. Our dialogue system is flexible and stable and responds to user requirements by controlling dialogue flow according to dialogue scenarios. We also improved user satisfaction by introducing motion and speech control based on system utterances and user situations. In the preliminary round, our system was ranked fifth in the impression evaluation and sixth in the plan evaluation among all 12 teams.

| Comments: | This paper is part of the proceedings of the Dialogue Robot Competition 2023 |
| --------- | ------------------------------------------------------------ |
| Subjects: | **Computation and Language (cs.CL)**                         |
| Cite as:  | **[arXiv:2312.12808](https://arxiv.org/abs/2312.12808) [cs.CL]** |
|           | (or **[arXiv:2312.12808v1](https://arxiv.org/abs/2312.12808v1) [cs.CL]** for this version) |





<h2 id="2023-12-21-7">7. Fine-tuning Large Language Models for Adaptive Machine Translation
</h2>

Title: [Fine-tuning Large Language Models for Adaptive Machine Translation](https://arxiv.org/abs/2312.12740)

Authors: [Yasmin Moslem](https://arxiv.org/search/cs?searchtype=author&query=Moslem,+Y), [Rejwanul Haque](https://arxiv.org/search/cs?searchtype=author&query=Haque,+R), [Andy Way](https://arxiv.org/search/cs?searchtype=author&query=Way,+A)

> This paper presents the outcomes of fine-tuning Mistral 7B, a general-purpose large language model (LLM), for adaptive machine translation (MT). The fine-tuning process involves utilising a combination of zero-shot and one-shot translation prompts within the medical domain. The primary objective is to enhance real-time adaptive MT capabilities of Mistral 7B, enabling it to adapt translations to the required domain at inference time. The results, particularly for Spanish-to-English MT, showcase the efficacy of the fine-tuned model, demonstrating quality improvements in both zero-shot and one-shot translation scenarios, surpassing Mistral 7B's baseline performance. Notably, the fine-tuned Mistral outperforms ChatGPT "gpt-3.5-turbo" in zero-shot translation while achieving comparable one-shot translation quality. Moreover, the zero-shot translation of the fine-tuned Mistral matches NLLB 3.3B's performance, and its one-shot translation quality surpasses that of NLLB 3.3B. These findings emphasise the significance of fine-tuning efficient LLMs like Mistral 7B to yield high-quality zero-shot translations comparable to task-oriented models like NLLB 3.3B. Additionally, the adaptive gains achieved in one-shot translation are comparable to those of commercial LLMs such as ChatGPT. Our experiments demonstrate that, with a relatively small dataset of 20,000 segments that incorporate a mix of zero-shot and one-shot prompts, fine-tuning significantly enhances Mistral's in-context learning ability, especially for real-time adaptive MT.

| Subjects: | **Computation and Language (cs.CL)**; Information Retrieval (cs.IR) |
| --------- | ------------------------------------------------------------ |
| Cite as:  | **[arXiv:2312.12740](https://arxiv.org/abs/2312.12740) [cs.CL]** |
|           | (or **[arXiv:2312.12740v1](https://arxiv.org/abs/2312.12740v1) [cs.CL]** for this version) |





<h2 id="2023-12-21-8">8. Learning and Forgetting Unsafe Examples in Large Language Models
</h2>

Title: [Learning and Forgetting Unsafe Examples in Large Language Models](https://arxiv.org/abs/2312.12736)

Authors: [Jiachen Zhao](https://arxiv.org/search/cs?searchtype=author&query=Zhao,+J), [Zhun Deng](https://arxiv.org/search/cs?searchtype=author&query=Deng,+Z), [David Madras](https://arxiv.org/search/cs?searchtype=author&query=Madras,+D), [James Zou](https://arxiv.org/search/cs?searchtype=author&query=Zou,+J), [Mengye Ren](https://arxiv.org/search/cs?searchtype=author&query=Ren,+M)

> As the number of large language models (LLMs) released to the public grows, there is a pressing need to understand the safety implications associated with these models learning from third-party custom finetuning data. We explore the behavior of LLMs finetuned on noisy custom data containing unsafe content, represented by datasets that contain biases, toxicity, and harmfulness, finding that while aligned LLMs can readily learn this unsafe content, they also tend to forget it more significantly than other examples when subsequently finetuned on safer content. Drawing inspiration from the discrepancies in forgetting, we introduce the "ForgetFilter" algorithm, which filters unsafe data based on how strong the model's forgetting signal is for that data. We demonstrate that the ForgetFilter algorithm ensures safety in customized finetuning without compromising downstream task performance, unlike sequential safety finetuning. ForgetFilter outperforms alternative strategies like replay and moral self-correction in curbing LLMs' ability to assimilate unsafe content during custom finetuning, e.g. 75% lower than not applying any safety measures and 62% lower than using self-correction in toxicity score.

| Subjects: | **Computation and Language (cs.CL)**; Machine Learning (cs.LG) |
| --------- | ------------------------------------------------------------ |
| Cite as:  | **[arXiv:2312.12736](https://arxiv.org/abs/2312.12736) [cs.CL]** |
|           | (or **[arXiv:2312.12736v1](https://arxiv.org/abs/2312.12736v1) [cs.CL]** for this version) |





<h2 id="2023-12-21-9">9. Turning English-centric LLMs Into Polyglots: How Much Multilinguality Is Needed?
</h2>

Title: [Turning English-centric LLMs Into Polyglots: How Much Multilinguality Is Needed?](https://arxiv.org/abs/2312.12683)

Authors: [Tannon Kew](https://arxiv.org/search/cs?searchtype=author&query=Kew,+T), [Florian Schottmann](https://arxiv.org/search/cs?searchtype=author&query=Schottmann,+F), [Rico Sennrich](https://arxiv.org/search/cs?searchtype=author&query=Sennrich,+R)

> The vast majority of today's large language models are English-centric, having been pretrained predominantly on English text. Yet, in order to meet user expectations, models need to be able to respond appropriately in multiple languages once deployed in downstream applications. Given limited exposure to other languages during pretraining, cross-lingual transfer is important for achieving decent performance in non-English settings. In this work, we investigate just how much multilinguality is required during finetuning to elicit strong cross-lingual generalisation across a range of tasks and target languages. We find that, compared to English-only finetuning, multilingual instruction tuning with as few as three languages significantly improves a model's cross-lingual transfer abilities on generative tasks that assume input/output language agreement, while being of less importance for highly structured tasks. Our code and data is available at [this https URL](https://github.com/ZurichNLP/multilingual-instruction-tuning).

| Subjects: | **Computation and Language (cs.CL)**                         |
| --------- | ------------------------------------------------------------ |
| Cite as:  | **[arXiv:2312.12683](https://arxiv.org/abs/2312.12683) [cs.CL]** |
|           | (or **[arXiv:2312.12683v1](https://arxiv.org/abs/2312.12683v1) [cs.CL]** for this version) |





<h2 id="2023-12-21-10">10. Is post-editing really faster than human translation?
</h2>

Title: [Is post-editing really faster than human translation?](https://arxiv.org/abs/2312.12660)

Authors: [Silvia Terribile](https://arxiv.org/search/cs?searchtype=author&query=Terribile,+S)

> Time efficiency is paramount for the localisation industry, which demands ever-faster turnaround times. However, translation speed is largely underresearched, and there is a lack of clarity about how language service providers (LSPs) can evaluate the performance of their post-editing (PE) and human translation (HT) services. This study constitutes the first large-scale investigation of translation and revision speed in HT and in the PE of neural machine translation, based on real-world data from an LSP. It uses an exploratory data analysis approach to investigate data for 90 million words translated by 879 linguists across 11 language pairs, over 2.5 years. The results of this research indicate that (a) PE is usually but not always faster than HT; (b) average speed values may be misleading; (c) translation speed is highly variable; and (d) edit distance cannot be used as a proxy for post-editing productivity, because it does not correlate strongly with speed.

| Comments:    | 30 pages, 11 tables, 7 figures. This article has been published in Translation Spaces. This is the author accepted manuscript. Please find the published version at: [this https URL](https://doi.org/10.1075/ts.22044.ter) |
| ------------ | ------------------------------------------------------------ |
| Subjects:    | **Computation and Language (cs.CL)**                         |
| Cite as:     | **[arXiv:2312.12660](https://arxiv.org/abs/2312.12660) [cs.CL]** |
|              | (or **[arXiv:2312.12660v1](https://arxiv.org/abs/2312.12660v1) [cs.CL]** for this version) |
| Related DOI: | https://doi.org/10.1075/ts.22044.terFocus to learn more      |





<h2 id="2023-12-21-11">11. An Empirical study of Unsupervised Neural Machine Translation: analyzing NMT output, model's behavior and sentences' contribution
</h2>

Title: [An Empirical study of Unsupervised Neural Machine Translation: analyzing NMT output, model's behavior and sentences' contribution](https://arxiv.org/abs/2312.12588)

Authors: [Isidora Chara Tourni](https://arxiv.org/search/cs?searchtype=author&query=Tourni,+I+C), [Derry Wijaya](https://arxiv.org/search/cs?searchtype=author&query=Wijaya,+D)

> Unsupervised Neural Machine Translation (UNMT) focuses on improving NMT results under the assumption there is no human translated parallel data, yet little work has been done so far in highlighting its advantages compared to supervised methods and analyzing its output in aspects other than translation accuracy. We focus on three very diverse languages, French, Gujarati, and Kazakh, and train bilingual NMT models, to and from English, with various levels of supervision, in high- and low- resource setups, measure quality of the NMT output and compare the generated sequences' word order and semantic similarity to source and reference sentences. We also use Layer-wise Relevance Propagation to evaluate the source and target sentences' contribution to the result, expanding the findings of previous works to the UNMT paradigm.

| Subjects: | **Computation and Language (cs.CL)**                         |
| --------- | ------------------------------------------------------------ |
| Cite as:  | **[arXiv:2312.12588](https://arxiv.org/abs/2312.12588) [cs.CL]** |
|           | (or **[arXiv:2312.12588v1](https://arxiv.org/abs/2312.12588v1) [cs.CL]** for this version) |





<h2 id="2023-12-21-12">12. When Parameter-efficient Tuning Meets General-purpose Vision-language Models
</h2>

Title: [When Parameter-efficient Tuning Meets General-purpose Vision-language Models](https://arxiv.org/abs/2312.12458)

Authors: [Yihang Zhai](https://arxiv.org/search/cs?searchtype=author&query=Zhai,+Y), [Haixin Wang](https://arxiv.org/search/cs?searchtype=author&query=Wang,+H), [Jianlong Chang](https://arxiv.org/search/cs?searchtype=author&query=Chang,+J), [Xinlong Yang](https://arxiv.org/search/cs?searchtype=author&query=Yang,+X), [Jinan Sun](https://arxiv.org/search/cs?searchtype=author&query=Sun,+J), [Shikun Zhang](https://arxiv.org/search/cs?searchtype=author&query=Zhang,+S), [Qi Tian](https://arxiv.org/search/cs?searchtype=author&query=Tian,+Q)

> Instruction tuning has shown promising potential for developing general-purpose AI capabilities by using large-scale pre-trained models and boosts growing research to integrate multimodal information for creative applications. However, existing works still face two main limitations: the high training costs and heavy computing resource dependence of full model fine-tuning, and the lack of semantic information in instructions, which hinders multimodal alignment. Addressing these challenges, this paper proposes a novel approach to utilize Parameter-Efficient Tuning for generAl-purpose vision-Language models, namely PETAL. PETAL revolutionizes the training process by requiring only 0.5% of the total parameters, achieved through a unique mode approximation technique, which significantly reduces the training costs and reliance on heavy computing resources. Furthermore, PETAL enhances the semantic depth of instructions in two innovative ways: 1) by introducing adaptive instruction mixture-of-experts(MOEs), and 2) by fortifying the score-based linkage between parameter-efficient tuning and mutual information. Our extensive experiments across five multimodal downstream benchmarks reveal that PETAL not only outperforms current state-of-the-art methods in most scenarios but also surpasses full fine-tuning models in effectiveness. Additionally, our approach demonstrates remarkable advantages in few-shot settings, backed by comprehensive visualization analyses. Our source code is available at: https://github. com/melonking32/PETAL.

| Subjects: | **Computation and Language (cs.CL)**; Artificial Intelligence (cs.AI) |
| --------- | ------------------------------------------------------------ |
| Cite as:  | **[arXiv:2312.12458](https://arxiv.org/abs/2312.12458) [cs.CL]** |
|           | (or **[arXiv:2312.12458v1](https://arxiv.org/abs/2312.12458v1) [cs.CL]** for this version) |





<h2 id="2023-12-21-13">13. Stable Distillation: Regularizing Continued Pre-training for Low-Resource Automatic Speech Recognition
</h2>

Title: [Stable Distillation: Regularizing Continued Pre-training for Low-Resource Automatic Speech Recognition](https://arxiv.org/abs/2312.12783)

Authors: [Ashish Seth](https://arxiv.org/search/eess?searchtype=author&query=Seth,+A), [Sreyan Ghosh](https://arxiv.org/search/eess?searchtype=author&query=Ghosh,+S), [S. Umesh](https://arxiv.org/search/eess?searchtype=author&query=Umesh,+S), [Dinesh Manocha](https://arxiv.org/search/eess?searchtype=author&query=Manocha,+D)

> Continued self-supervised (SSL) pre-training for adapting existing SSL models to the target domain has shown to be extremely effective for low-resource Automatic Speech Recognition (ASR). This paper proposes Stable Distillation, a simple and novel approach for SSL-based continued pre-training that boosts ASR performance in the target domain where both labeled and unlabeled data are limited. Stable Distillation employs self-distillation as regularization for continued pre-training, alleviating the over-fitting issue, a common problem continued pre-training faces when the source and target domains differ. Specifically, first, we perform vanilla continued pre-training on an initial SSL pre-trained model on the target domain ASR dataset and call it the teacher. Next, we take the same initial pre-trained model as a student to perform continued pre-training while enforcing its hidden representations to be close to that of the teacher (via MSE loss). This student is then used for downstream ASR fine-tuning on the target dataset. In practice, Stable Distillation outperforms all our baselines by 0.8 - 7 WER when evaluated in various experimental settings.

| Comments: | Accepted to ICASSP 2024. Code: [this https URL](https://github.com/cs20s030/stable_distillation) |
| --------- | ------------------------------------------------------------ |
| Subjects: | **Audio and Speech Processing (eess.AS)**; Artificial Intelligence (cs.AI); Computation and Language (cs.CL); Sound (cs.SD) |
| Cite as:  | **[arXiv:2312.12783](https://arxiv.org/abs/2312.12783) [eess.AS]** |
|           | (or **[arXiv:2312.12783v1](https://arxiv.org/abs/2312.12783v1) [eess.AS]** for this version) |





<h2 id="2023-12-21-14">14. Towards Better Serialization of Tabular Data for Few-shot Classification
</h2>

Title: [Towards Better Serialization of Tabular Data for Few-shot Classification](https://arxiv.org/abs/2312.12464)

Authors: [Sukriti Jaitly](https://arxiv.org/search/cs?searchtype=author&query=Jaitly,+S), [Tanay Shah](https://arxiv.org/search/cs?searchtype=author&query=Shah,+T), [Ashish Shugani](https://arxiv.org/search/cs?searchtype=author&query=Shugani,+A), [Razik Singh Grewal](https://arxiv.org/search/cs?searchtype=author&query=Grewal,+R+S)

> We present a study on the integration of Large Language Models (LLMs) in tabular data classification, emphasizing an efficient framework. Building upon existing work done in TabLLM ([arXiv:2210.10723](https://arxiv.org/abs/2210.10723)), we introduce three novel serialization techniques, including the standout LaTeX serialization method. This method significantly boosts the performance of LLMs in processing domain-specific datasets, Our method stands out for its memory efficiency and ability to fully utilize complex data structures. Through extensive experimentation, including various serialization approaches like feature combination and importance, we demonstrate our work's superiority in accuracy and efficiency over traditional models.

| Comments: | 4 pages, 2 figures                                           |
| --------- | ------------------------------------------------------------ |
| Subjects: | **Machine Learning (cs.LG)**; Artificial Intelligence (cs.AI); Computation and Language (cs.CL) |
| Cite as:  | **[arXiv:2312.12464](https://arxiv.org/abs/2312.12464) [cs.LG]** |
|           | (or **[arXiv:2312.12464v1](https://arxiv.org/abs/2312.12464v1) [cs.LG]** for this version) |



# 2023-11-30

[Return to Index](#Index)



<h2 id="2023-11-30-1">1. SenTest: Evaluating Robustness of Sentence Encoders
</h2>

Title: [SenTest: Evaluating Robustness of Sentence Encoders](https://arxiv.org/abs/2311.17722)

Authors: [Tanmay Chavan](https://arxiv.org/search/cs?searchtype=author&query=Chavan,+T), [Shantanu Patankar](https://arxiv.org/search/cs?searchtype=author&query=Patankar,+S), [Aditya Kane](https://arxiv.org/search/cs?searchtype=author&query=Kane,+A), [Omkar Gokhale](https://arxiv.org/search/cs?searchtype=author&query=Gokhale,+O), [Geetanjali Kale](https://arxiv.org/search/cs?searchtype=author&query=Kale,+G), [Raviraj Joshi](https://arxiv.org/search/cs?searchtype=author&query=Joshi,+R)

> Contrastive learning has proven to be an effective method for pre-training models using weakly labeled data in the vision domain. Sentence transformers are the NLP counterparts to this architecture, and have been growing in popularity due to their rich and effective sentence representations. Having effective sentence representations is paramount in multiple tasks, such as information retrieval, retrieval augmented generation (RAG), and sentence comparison. Keeping in mind the deployability factor of transformers, evaluating the robustness of sentence transformers is of utmost importance. This work focuses on evaluating the robustness of the sentence encoders. We employ several adversarial attacks to evaluate its robustness. This system uses character-level attacks in the form of random character substitution, word-level attacks in the form of synonym replacement, and sentence-level attacks in the form of intra-sentence word order shuffling. The results of the experiments strongly undermine the robustness of sentence encoders. The models produce significantly different predictions as well as embeddings on perturbed datasets. The accuracy of the models can fall up to 15 percent on perturbed datasets as compared to unperturbed datasets. Furthermore, the experiments demonstrate that these embeddings does capture the semantic and syntactic structure (sentence order) of sentences. However, existing supervised classification strategies fail to leverage this information, and merely function as n-gram detectors.

| Subjects: | **Computation and Language (cs.CL)**; Machine Learning (cs.LG) |
| --------- | ------------------------------------------------------------ |
| Cite as:  | [arXiv:2311.17722](https://arxiv.org/abs/2311.17722) [cs.CL] |
|           | (or [arXiv:2311.17722v1](https://arxiv.org/abs/2311.17722v1) [cs.CL] for this version) |
|           | https://doi.org/10.48550/arXiv.2311.17722Focus to learn more |

